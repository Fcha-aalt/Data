---
SCOPUS_ID: 85181807035
Title: "Regret Analysis of Learning-Based MPC With Partially-Unknown Cost Function"
Author: "Dogan I."
Journal: "IEEE Transactions on Automatic Control"
Publication Date: {'$date': '2023-01-01T00:00:00Z'}
Publication Year: 2023
DOI: "10.1109/TAC.2023.3328827"
Source Type: "Journal"
Document Type: "ar"
Document Type Description: "Article"
Affiliation: "University of California, Berkeley"
Affiliation Country: "United States"
Cited by count: 0
---

## Abstract
"The exploration/exploitation trade-off is an inherent challenge in data-driven adaptive control. Though this trade-off has been studied for multi-armed bandits (MAB&#x0027;s) and reinforcement learning for linear systems; it is less well-studied for learning-based control of nonlinear systems. A significant theoretical challenge in the nonlinear setting is that there is no explicit characterization of an optimal controller for a given set of cost and system parameters. We propose the use of a finite-horizon oracle controller with full knowledge of parameters as a reasonable surrogate to optimal controller. This allows us to develop policies in the context of learning-based MPC and MAB&#x0027;s and conduct a control-theoretic analysis using techniques from MPC- and optimization-theory to show these policies achieve low regret with respect to this finite-horizon oracle. Our simulations exhibit the low regret of our policy on a heating, ventilation, and air-conditioning model with partially-unknown cost function."
