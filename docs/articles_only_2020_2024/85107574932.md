---
SCOPUS_ID: 85107574932
Title: "Experimental evaluation of model-free reinforcement learning algorithms for continuous HVAC control"
Author: "Biemann M."
Journal: "Applied Energy"
Publication Date: {'$date': '2021-09-15T00:00:00Z'}
Publication Year: 2021
DOI: "10.1016/j.apenergy.2021.117164"
Source Type: "Journal"
Document Type: "ar"
Document Type Description: "Article"
Affiliation: "Norges Teknisk-Naturvitenskapelige Universitet"
Affiliation Country: "Norway"
Cited by count: 63
---

## Abstract
"Controlling heating, ventilation and air-conditioning (HVAC) systems is crucial to improving demand-side energy efficiency. At the same time, the thermodynamics of buildings and uncertainties regarding human activities make effective management challenging. While the concept of model-free reinforcement learning demonstrates various advantages over existing strategies, the literature relies heavily on value-based methods that can hardly handle complex HVAC systems. This paper conducts experiments to evaluate four actor-critic algorithms in a simulated data centre. The performance evaluation is based on their ability to maintain thermal stability while increasing energy efficiency and on their adaptability to weather dynamics. Because of the enormous significance of practical use, special attention is paid to data efficiency. Compared to the model-based controller implemented into EnergyPlus, all applied algorithms can reduce energy consumption by at least 10% by simultaneously keeping the hourly average temperature in the desired range. Robustness tests in terms of different reward functions and weather conditions verify these results. With increasing training, we also see a smaller trade-off between thermal stability and energy reduction. Thus, the Soft Actor Critic algorithm achieves a stable performance with ten times less data than on-policy methods. In this regard, we recommend using this algorithm in future experiments, due to both its interesting theoretical properties and its practical results."
