---
SCOPUS_ID: 85144240645
Title: "Deep Reinforcement Learning for Joint Datacenter and HVAC Load Control in Distributed Mixed-Use Buildings"
Author: "Wei T."
Journal: "IEEE Transactions on Sustainable Computing"
Publication Date: {'$date': '2021-07-01T00:00:00Z'}
Publication Year: 2021
DOI: "10.1109/TSUSC.2019.2910533"
Source Type: "Journal"
Document Type: "ar"
Document Type Description: "Article"
Affiliation: "Marlan and Rosemary Bourns College of Engineering"
Affiliation Country: "United States"
Cited by count: 26
---

## Abstract
"The majority of today's power-hungry datacenters are physically co-located with office rooms in mixed-use buildings (MUBs). The heating, ventilation, and air conditioning (HVAC) system within each MUB is often shared or partially-shared between datacenter rooms and office zones, for removing the heat generated by computing equipment and maintaining desired room temperature for building tenants. To effectively reduce the total energy cost of MUBs, it is important to leverage the scheduling flexibility in both the HVAC system and the datacenter workload. In this work, we formulate both HVAC control and datacenter workload scheduling as a Markov decision process (MDP), and propose a deep reinforcement learning (DRL) based algorithm for minimizing the total energy cost while maintaining desired room temperature and meeting datacenter workload deadline constraints. Moreover, we also develop a heuristic DRL-based algorithm to enable interactive workload allocation among geographically distributed MUBs for further energy reduction. The experiment results demonstrate that our regular DRL-based algorithm can achieve up to 26.9 percent cost reduction for a single MUB, when compared with a baseline strategy. Our heuristic DRL-based algorithm can reduce the total energy cost by an additional 5.5 percent, when intelligently allocating interactive workload for multiple geographically distributed MUBs."
