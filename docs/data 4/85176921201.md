---
SCOPUS_ID: 85176921201
Title: "1st World Conference on eXplainable Artificial Intelligence, xAI 2023"
Author: nan
Journal: "Communications in Computer and Information Science"
Publication Date: {'$date': '2023-01-01T00:00:00Z'}
Publication Year: 2023
DOI: nan
Source Type: "Book Series"
Document Type: "cr"
Document Type Description: "Conference Review"
Affiliation: nan
Affiliation Country: nan
Cited by count: 0
---

## Abstract
"The proceedings contain 58 papers. The special focus in this conference is on eXplainable Artificial Intelligence. The topics include: Closing the Loop: Testing ChatGPT to Generate Model Explanations to Improve Human Labelling of Sponsored Content on Social Media; human-Computer Interaction and Explainability: Intersection and Terminology; Explaining Deep Reinforcement Learning-Based Methods for Control of Building HVAC Systems; handling Missing Values in Local Post-hoc Explainability; necessary and Sufficient Explanations of Multi-Criteria Decision Aiding Models, with and Without Interacting Criteria; XInsight: Revealing Model Insights for GNNs with Flow-Based Explanations; What Will Make Misinformation Spread: An XAI Perspective; MEGAN: Multi-explanation Graph Attention Network; quantifying the Intrinsic Usefulness of Attributional Explanations for Graph Neural Networks with Artificial Simulatability Studies; natural Example-Based Explainability: A Survey; evaluating Link Prediction Explanations for Graph Neural Networks; Propaganda Detection Robustness Through Adversarial Attacks Driven by eXplainable AI; explainable Automated Anomaly Recognition in Failure Analysis: is Deep Learning Doing it Correctly?; DExT: Detector Explanation Toolkit; unveiling Black-Boxes: Explainable Deep Learning Models for Patent Classification; HOLMES: HOLonym-MEronym Based Semantic Inspection for Convolutional Image Classifiers; Evaluating the Stability of Semantic Concept Representations in CNNs for Robust Explainability; beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers; finding Spurious Correlations with Function-Semantic Contrast Analysis; explaining Search Result Stances to Opinionated People; explainable Artificial Intelligence in Education: A Comprehensive Review; a Co-design Study for Multi-stakeholder Job Recommender System Explanations; explaining Socio-Demographic and Behavioral Patterns of Vaccination Against the Swine Flu (H1N1) Pandemic; semantic Meaningfulness: Evaluating Counterfactual Approaches for Real-World Plausibility and Feasibility; contrastive Visual Explanations for Reinforcement Learning via Counterfactual Rewards; Compare-xAI: Toward Unifying Functional Testing Methods for Post-hoc XAI Algorithms into a Multi-dimensional Benchmark; explainability in Practice: Estimating Electrification Rates from Mobile Phone Data in Senegal; explaining Black-Boxes in Federated Learning; PERFEX: Classifier Performance Explanations for Trustworthy AI Systems."
